{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Acquistion from Reddit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go to <a href=#bookmark>bookmark</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2019-06-08 - Goal - Develop End-to-End Data Flow, at least at small scale.\n",
    "# OR BUST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://images.unsplash.com/photo-1515255384510-23e8b6a6ca3c?ixlib=rb-1.2.1&auto=format&fit=crop&w=1489&q=80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install libs on this computer:\n",
    "# !pip install praw\n",
    "# !pip install pymongo\n",
    "# !pip install psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os             # file system stuff\n",
    "import json           # digest json\n",
    "import praw           # reddit API\n",
    "import pandas as pd   # Dataframes\n",
    "import pymongo        # MongoDB\n",
    "import numpy as np    # math and arrays\n",
    "\n",
    "import time           # To time stuff\n",
    "\n",
    "#DATA STORAGE\n",
    "from sqlalchemy import create_engine # SQL helper\n",
    "import psycopg2 as psql #PostgreSQL DBs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import helper     # Custom helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1A Load Reddit keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Create your first Authorized Reddit Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/werlindo/.secret/reddit.json'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define path to secret\n",
    "\n",
    "secret_path = os.path.join(os.environ['HOME'], '.secret', 'reddit.json')\n",
    "#secret_path = os.path.join(os.environ['HOME'], 'mia/.secret', 'reddit_api.json')\n",
    "\n",
    "secret_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save submissions to DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/werlindo/.secret/aws_ps_flatiron.json'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define path to secret\n",
    "\n",
    "secret_path_aws = os.path.join(os.environ['HOME'], '.secret', \n",
    "                           'aws_ps_flatiron.json')\n",
    "secret_path_aws"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1B Load AWS-PostgreSQL DB keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "aws_keys = helper.get_keys(secret_path_aws)\n",
    "user = aws_keys['user']\n",
    "ps = aws_keys['password']\n",
    "host = aws_keys['host']\n",
    "db = aws_keys['db_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "aws_ps_engine = ('postgresql://' + user + ':' + ps + '@' + host + '/' + db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use SQLAlchemy to create PSQL engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dialect+driver://username:password@host:port/database\n",
    "sql_alch_engine = create_engine(aws_ps_engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Load keys, Create Reddit Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = helper.get_keys(secret_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit = praw.Reddit(client_id=keys['client_id'] \n",
    "                     ,client_secret=keys['api_key']\n",
    "                     ,username=keys['username']\n",
    "                     ,password=keys['password']\n",
    "                     ,user_agent='reddit_research accessAPI:v0.0.1 (by /u/FlatDubs)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize parameters for this submissions pull"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://en.wikipedia.org/wiki/List_of_Game_of_Thrones_characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "subreddit_nm = 'gameofthrones'\n",
    "\n",
    "# query = \"\"\"\n",
    "#         \"qyburn\" OR \"yara\"\n",
    "        \n",
    "#         \"\"\"\n",
    "\n",
    "query = \"harry strickland\"\n",
    "\n",
    "results_lim = 1\n",
    "\n",
    "nm_subs_tbl = 'got_subs'\n",
    "\n",
    "nm_comms_tbl = 'got_comms'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get subreddit submissions and their comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - Obtain a Subreddit Instance(s) from your Reddit Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subs_df(praw_reddit\n",
    "                ,subreddit_nm='all'\n",
    "                ,query=''\n",
    "                ,results_lim=1000\n",
    "               ):\n",
    "    \"\"\"\n",
    "    Query a subreddit and return a dataframe of submissions\n",
    "    Parameters:\n",
    "    -----------\n",
    "    praw_reddit: pre-instantiated praw Reddit class\n",
    "    subreddit_nm: name of subreddit to search\n",
    "    query: query string to search on\n",
    "    results_lim: number of submissions results to return\n",
    "    \n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    Pandas dataframe of submissions\n",
    "    \"\"\"\n",
    "\n",
    "    # Instantiate subreddit\n",
    "    subred = praw_reddit.subreddit(subreddit_nm) \n",
    "    \n",
    "\n",
    "    # Get Search generator\n",
    "    search_results = subred.search(query, \n",
    "                            sort='comments',\n",
    "                           limit=results_lim\n",
    "                           ,time_filter='month')\n",
    "\n",
    "\n",
    "    # Compile submission into list\n",
    "    title = [] \n",
    "    num_comments = []\n",
    "    upvote_ratio = []\n",
    "    sub_id = []\n",
    "    i=0\n",
    "\n",
    "    # Loop through generator and get data\n",
    "    for submission in search_results:\n",
    "        i+=1\n",
    "        title.append(submission.title)\n",
    "        num_comments.append(submission.num_comments)\n",
    "        upvote_ratio.append(submission.upvote_ratio)\n",
    "        sub_id.append(submission.id)\n",
    "        if i%100 == 0:\n",
    "            print(f'{i} submissions completed')\n",
    "\n",
    "    # Make dataframe to hold results        \n",
    "    df_subs = pd.DataFrame(\n",
    "        {'title': title,\n",
    "         'num_comments': num_comments,\n",
    "         'upvote_ratio': upvote_ratio,\n",
    "         'id':sub_id\n",
    "        })\n",
    "\n",
    "    return df_subs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_comms_df(praw_reddit, list_sub_ids=[]):\n",
    "    \"\"\"\n",
    "    Query a list of submission id's get the comments for each submission\n",
    "    and store in dataframe\n",
    "    Parameters:\n",
    "    -----------\n",
    "    praw_reddit: pre-instantiated praw Reddit class\n",
    "    list_sub_ids: list of submission ids\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    Pandas dataframe of comments\n",
    "    \"\"\"    \n",
    "    # List to hold all the comments dfs\n",
    "    comm_dfs = []\n",
    "\n",
    "    # Loop through list sub ids and get comments data\n",
    "    for this_sub_id in list_sub_ids:\n",
    "        subm = praw_reddit.submission(id=this_sub_id)\n",
    "        \n",
    "        # Instantiate lists to hold comments data\n",
    "        comment_body = []\n",
    "        comment_id = []\n",
    "        sub_id = []\n",
    "\n",
    "        # Force loading comments until maxed out\n",
    "        while True:\n",
    "            try:\n",
    "                subm.comments.replace_more()\n",
    "                break\n",
    "            except PossibleExceptions:\n",
    "                print('Handling replace_more exception')\n",
    "                sleep(1)\n",
    "\n",
    "        # Loop through comments and put into list\n",
    "        \n",
    "        for comment in subm.comments.list():\n",
    "            comment_id.append(comment.id)\n",
    "            comment_body.append(comment.body)\n",
    "            sub_id.append(this_sub_id)\n",
    "            \n",
    "        # create df from lists\n",
    "        this_df = pd.DataFrame({\n",
    "            'comment': comment_body,\n",
    "            'comment_id':comment_id,\n",
    "            'sub_id':sub_id\n",
    "        })\n",
    "\n",
    "        # Add this sub's comments df to list of dfs\n",
    "        comm_dfs.append(this_df)\n",
    "        \n",
    "        # Combine the list of dataframes\n",
    "        df_combined = pd.concat(comm_dfs, axis=0).reset_index(drop=True)\n",
    "        \n",
    "    return df_combined\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subred_subs_coms(praw_reddit\n",
    "                         ,sql_alch_engine \n",
    "                         ,subreddit_nm='all'\n",
    "                         ,query=''\n",
    "                         ,results_lim=1000\n",
    "                         ,nm_subs_tbl=subreddit_nm + '_subs'\n",
    "                         ,nm_comms_tbl=subreddit_nm + '_comms'\n",
    "                         ):\n",
    "    \"\"\"\n",
    "    Given the name of a subreddit and search terms, get submissions and their \n",
    "    related comments and save them to an AWS DB\n",
    "    Parameters\n",
    "    ---------\n",
    "    praw_reddit: pre-instantiated praw Reddit class\n",
    "    subreddit_nm: name of subreddit to search\n",
    "    query: query string to search on\n",
    "    results_lim: number of submissions results to return\n",
    "    nm_subs_tbl: name of the submissions table\n",
    "    nm_comms_tbl: name of the comments table\n",
    "    sql_alc_engine: SQLAlchemy engine, for pandas to connect \n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    No return object, but will print success\n",
    "    \"\"\"\n",
    "\n",
    "    # Start timing\n",
    "    start_time = time.time()\n",
    "    now = time.ctime(int(time.time()))\n",
    "    print('Starting: ' + str(now) + '\\n')\n",
    "   \n",
    "    # Get Submissions dataframe\n",
    "    subs_df = get_subs_df(praw_reddit=praw_reddit\n",
    "                          ,subreddit_nm=subreddit_nm\n",
    "                          ,query=query\n",
    "                          ,results_lim=results_lim)\n",
    "    \n",
    "    print(\"Retrieved submissions.\")\n",
    "    \n",
    "    # Get just submissions IDs\n",
    "    list_sub_ids = subs_df['id'].tolist()\n",
    "    \n",
    "    # Get comments dataframe\n",
    "    comms_df = get_comms_df(praw_reddit=praw_reddit\n",
    "                            ,list_sub_ids=list_sub_ids)\n",
    "    \n",
    "    \n",
    "    print(\"Retrieved comments.\")\n",
    "\n",
    "    # Write dataframes out to SQL DB\n",
    "    subs_df.to_sql(nm_subs_tbl, con=sql_alch_engine, if_exists='append')\n",
    "    comms_df.to_sql(nm_comms_tbl, con=sql_alch_engine, if_exists='append')\n",
    "#     print('write to ' + nm_subs_tbl)\n",
    "#     print('write to ' + nm_comms_tbl)\n",
    "\n",
    "    # Timing Stuff\n",
    "    end_time = time.time()\n",
    "    now = time.ctime(int(time.time()))\n",
    "    print('\\nFinished: ' + str(now) + '\\n')\n",
    "\n",
    "    mins_to_complete = (end_time - start_time)/60 \n",
    "    print(\"It took {:.2f} minutes to complete.\".format(mins_to_complete))\n",
    "    print(\"There were {} submissions added.\".format(subs_df.shape[0]))\n",
    "    print(\"There were {:,} comments added.\".format(comms_df.shape[0]))\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting: Sun Jun  9 21:25:36 2019\n",
      "\n",
      "Retrieved submissions.\n",
      "Retrieved comments.\n",
      "write to got_subs\n",
      "write to got_comms\n",
      "\n",
      "Finished: Sun Jun  9 21:25:39 2019\n",
      "\n",
      "It took 0.04 minutes to complete.\n",
      "There were 1 submissions added.\n",
      "There were 26 comments added.\n"
     ]
    }
   ],
   "source": [
    "get_subred_subs_coms(praw_reddit=reddit\n",
    "                    ,sql_alch_engine=sql_alch_engine\n",
    "                    ,subreddit_nm=subreddit_nm\n",
    "                    ,query=query\n",
    "                    ,results_lim=results_lim\n",
    "                    ,nm_subs_tbl='got_subs'\n",
    "                    ,nm_comms_tbl='got_comms'\n",
    "                    ,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "persons = \"\"\"\"\n",
    "doran\" OR \"davos\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "persons = \"\"\"\n",
    "            \"bran\" OR 'brandon stark' OR 'jon snow' OR 'jon' \n",
    "                         OR 'khaleesi' OR 'dany' OR 'daenerys' OR 'danyris'\n",
    "          \"\"\"\n",
    "          \n",
    "It took 14.21 minutes to complete.\n",
    "There were 249 submissions added.\n",
    "There were 11272 comments added."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "persons = \"\"\"\n",
    "            \"cersei\" OR 'tyrion' OR 'sansa' OR 'arya' \n",
    "                        OR 'stannis' OR 'varys' OR 'jamie' OR 'brienne'\n",
    "\"\"\"\n",
    "\n",
    "It took 92.47 minutes to complete.  \n",
    "There were 246 submissions added.  \n",
    "There were 65,896 comments added."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "persons = \"\"\"\n",
    "            \"samwell\" OR \"jorah\" OR \"theon\" OR \"hound\" OR \"littlefinger\" \n",
    "          \"\"\"\n",
    "\n",
    "It took 30.70 minutes to complete.  \n",
    "There were 246 submissions added.  \n",
    "There were 30,374 comments added.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bookmark! <a name='bookmark' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://images.unsplash.com/photo-1534224563519-fea04849cadf?ixlib=rb-1.2.1&ixid=eyJhcHBfaWQiOjEyMDd9&auto=format&fit=crop&w=1350&q=80\n",
    " )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://images.unsplash.com/photo-1553058296-61093581de13?ixlib=rb-1.2.1&ixid=eyJhcHBfaWQiOjEyMDd9&auto=format&fit=crop&w=1351&q=80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### f. Check that the table was created, or can be appended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup PSQL connection\n",
    "conn = psql.connect(\n",
    "    database=db,\n",
    "    user=user,\n",
    "    password=ps,\n",
    "    host=host,\n",
    "    port='5432'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QUERY TO GET LIST OF TABLES\n",
    "# query = \"\"\"\n",
    "#     SELECT * FROM pg_catalog.pg_tables\n",
    "#     WHERE schemaname = 'public';\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate cursor\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up query\n",
    "query = \"\"\"\n",
    "    SELECT count(*) ct FROM got_comms;\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute the query\n",
    "cur.execute(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conn.rollback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check results\n",
    "df_clone = pd.DataFrame(cur.fetchall())\n",
    "df_clone.columns = [col.name for col in cur.description]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
